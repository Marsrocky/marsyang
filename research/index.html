<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Research - Jianfei Yang</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Research" />
<meta property="og:description" content="Research Interests My Research mainly focuses on Artificial Intelligence of Things (AIoT), where the state-of-the-art AI models are proposed and implemented in the edge computing and enables everything interconnected. Broadly speaking, I study how AI models empower IoT-enabled edge devices to sense the environment (i.e. Smart Sensing), how AI models are efficiently deployed in resource-restrained devices (i.e. Efficient AI Systems), and how multimodal data from IoT sensors can be represented and engineered to support decision-making (i." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/research/" /><meta property="article:section" content="" />




	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/mystyle.css">

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="Jianfei Yang" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">Jianfei Yang</div>
					<div class="logo__tagline">Science is the only way to magic.</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/">
				
				<span class="menu__text">Home</span>
				
			</a>
		</li>
		<li class="menu__item menu__item--active">
			<a class="menu__link" href="/research/">
				
				<span class="menu__text">Research</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/publications/">
				
				<span class="menu__text">Publications</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/award/">
				
				<span class="menu__text">Awards</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/group/">
				
				<span class="menu__text">Group</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/services/">
				
				<span class="menu__text">Services</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/patents/">
				
				<span class="menu__text">Patents</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>


		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Research</h1>
			
		</header>
		<div class="content post__content clearfix">
			<hr>
<h3 id="research-interests">Research Interests</h3>
<p>My Research mainly focuses on <strong>Artificial Intelligence of Things (AIoT)</strong>, where the state-of-the-art AI models are proposed and implemented in the edge computing and enables everything interconnected. Broadly speaking, I study how AI models empower IoT-enabled edge devices to sense the environment (i.e. <strong>Smart Sensing</strong>), how AI models are efficiently deployed in resource-restrained devices (i.e. <strong>Efficient AI Systems</strong>), and how multimodal data from IoT sensors can be represented and engineered to support decision-making (i.e. <strong>Multimodal Learning</strong>).</p>
<p>Revolving these goals, my team mainly studies the following topics:</p>
<ul>
<li><strong>Deep Learning for IoT-enabled Smart Sensing</strong>: The state-of-the-art deep learning models empower better representation learning and difficult tasks for smart sensing such as device-free human activity recognition, gesture recognition and human vital sign detection. Though massive deep models have been explored for camera data, it is worth exploring many other IoT sensor data, such as mmWave radar, WiFi signals and ultra-wideband (UWB). To this end, we develop deep learning, transfer learning, few-shot learning and self-supervised learning algorithms to enable cost-effective, data-efficient, privacy-preserving and fine-grained smart sensing technology.</li>
<li><strong>Multimodal Learning for Robust Sensing</strong>: In smart sensing, a single modality can have main flaws when confronting some situations. For instance, visual recognition models cannot work well in the face of bad illumination or occlusion, which can be overcome by wireless sensing (e.g. WiFi or radar). To leverage the complementarity of various modalities, we propose multimodal learning algorithms for robust smart sensing under kinds of circumstances 24/7.</li>
<li><strong>Efficient AI Systems</strong>: To improve the performance, deeper and deeper networks have been proposed, while for smart sensing via edge computing, AI models should be simple enough to run in the real-time systems, which denotes our objective. We develop efficient deep models on real-time systems on cost-effective edge computational devices such as Raspberry Pi and NVIDIA Jetson Nano. Based on them, everything can be interconnected.</li>
</ul>
<hr>
<h3 id="research-projects">Research Projects</h3>
<ul>
<li><strong>WiFi-based Human Sensing System</strong>: We build a WiFi-based sensing system based on off-the-shelf WiFi routers and chips that can extract fine-grained channel state information for human sensing. Via WiFi signals, human poses and activities are recognized through walls, which enables security and healthcare applications. We have collabroated projects with Panasonic and Singapore Airelines.</li>
<li><strong>Multimodal Learning and Systems</strong>: We build the multimodal sensing system integrating radar, camera and WiFi in our lab. Multimodal learning algorithms are proposed for various sensing applications, such as human sensing or autonomous driving.</li>
<li><strong>Data-Efficient Machine Learning</strong>: To overcome the lack of data issue, we study transfer learning, domain adaptation and unsupervised learning for visual recognition and wireless sensing.</li>
</ul>
<hr>
<h3 id="collaborations">Collaborations</h3>
<p>I am interested in collaboration with respect to the following directions:</p>
<ul>
<li>IoT-enabled Human Sensing and Its Applications for Smart Home and Healthcare</li>
<li>Affective Computing via Computer Vision and IoT Sensors</li>
<li>Deep Learning and Transfer Learning Algorithms and Applications for Interdisciplinary Research</li>
</ul>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2022 Jianfei Yang.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>